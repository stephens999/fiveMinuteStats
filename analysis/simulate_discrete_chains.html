<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Matt Bonakdarpour" />

<meta name="date" content="2016-01-21" />

<title>Simulating Discrete Markov Chains</title>

<script src="libs/jquery-1.11.0/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.1/css/united.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.1/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.1/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.1/shim/respond.min.js"></script>

<style type="text/css">

/* padding for bootstrap navbar */
body {
  padding-top: 50px;
  padding-bottom: 40px;
}


/* offset scroll position for anchor links (for fixed navbar)  */
.section h2 {
  padding-top: 55px;
  margin-top: -55px;
}
.section h3 {
  padding-top: 55px;
  margin-top: -55px;
}



/* don't use link color in navbar */
.dropdown-menu>li>a {
  color: black;
}

/* some padding for disqus */
#disqus_thread {
  margin-top: 45px;
}

</style>

<link rel="stylesheet" href="libs/font-awesome-4.1.0/css/font-awesome.min.css"/>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="libs/highlight/textmate.css"
      type="text/css" />
<script src="libs/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img { 
  max-width:100%; 
  height: auto; 
}
</style>
<div class="container-fluid main-container">


<div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">fiveMinuteStats</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li><a href="index.html">Home</a></li>
        <li><a href="about.html">About</a></li>
        <li><a href="license.html">License</a></li>
        <li><a href="https://github.com/stephens999/fiveMinuteStats">GitHub</a></li>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">
<h1 class="title">Simulating Discrete Markov Chains</h1>
<h4 class="author"><em>Matt Bonakdarpour</em></h4>
<h4 class="date"><em>2016-01-21</em></h4>
</div>

<div id="TOC">
<ul>
<li><a href="#pre-requisites">Pre-requisites</a></li>
<li><a href="#illustrative-example">Illustrative Example</a><ul>
<li><a href="#general-algorithm">General Algorithm</a></li>
</ul></li>
<li><a href="#limiting-probabilities">Limiting Probabilities</a></li>
<li><a href="#simulation-1-3x3-example">Simulation 1: 3x3 example</a><ul>
<li><a href="#finding-the-stationary-distribution">Finding the stationary distribution</a></li>
<li><a href="#the-limiting-distribution">The limiting distribution</a></li>
</ul></li>
<li><a href="#simulation-2-8x8-example">Simulation 2: 8x8 example</a></li>
<li><a href="#session-information">Session information</a></li>
</ul>
</div>

<p><strong>Last updated:</strong> 2016-01-26</p>
<p><strong>Code version:</strong> 0af3bd3542e3289a32c8722edfe68298c1c1f1dc</p>
<div id="pre-requisites" class="section level1">
<h1>Pre-requisites</h1>
<p>This document assumes basic familiarity with Markov chains and linear algebra.</p>
</div>
<div id="illustrative-example" class="section level1">
<h1>Illustrative Example</h1>
<p>In this note, we will simulate Markov chains to gain some intuition about their behavior and how they evolve. Before moving on to concrete examples, we first settle on notation and implement an R function which will facilitate the simulations.</p>
<p>Let <span class="math">\(P_{ij}\)</span> denote the one-step transition probability. That is, <span class="math">\[ P_{ij} = P(X_{n+1} = j | X_{n} = i)\]</span></p>
<p>In what follows, we will assume that the transition probabilities do not depend on the time <span class="math">\(n\)</span>. These are called <em>time homogenous</em> Markov chains.</p>
<p>The general idea of simulating discrete Markov chains can be illustrated through a simple example with 2 states. Assume our state space is <span class="math">\(\{1,2\}\)</span> and the transition matrix is:</p>
<p><span class="math">\[P = \begin{bmatrix}
    0.7 &amp; 0.3 \\
    0.4 &amp; 0.6
\end{bmatrix}\]</span></p>
<p>Further assume that our Markov chain starts in state 1 so that <span class="math">\(X_0 = 1\)</span>. Since we are starting in state 1, our chain can either remain in state <span class="math">\(1\)</span> with probability <span class="math">\(P_{11}\)</span> or transition to state <span class="math">\(2\)</span> with probability <span class="math">\(P_{12}\)</span>. Therefore, to simulate <span class="math">\(X_1\)</span>, we need to generate a random variable according to the first row of <span class="math">\(P\)</span> so that <span class="math">\(P_{11}= P(X_1 = 1 | X_0 = 1) = 0.7\)</span> and <span class="math">\(P_{12} = P(X_1 = 2 | X_0 = 0) = 0.7\)</span>.</p>
<p>To simulate <span class="math">\(X_1\)</span> with these known probabilities, we could use inverse transform sampling by first generating a uniform random variable <span class="math">\(U\)</span> between <span class="math">\(0\)</span> and <span class="math">\(1\)</span>. Then, we set <span class="math">\(X_1=1\)</span> if <span class="math">\(U \leq 0.7\)</span> and <span class="math">\(X_1=2\)</span> if <span class="math">\(U &gt; 0.7\)</span>. If it happens that <span class="math">\(X_1 = 2\)</span>, we would then generate <span class="math">\(X_2\)</span> according to the second row of <span class="math">\(P\)</span> in a similar fashion.</p>
<p>For larger state spaces, if <span class="math">\(X_n = i\)</span>, we would simulate <span class="math">\(X_{n+1}\)</span> according to the <span class="math">\(i\)</span>-th row of the probability transition matrix. Using the inverse transform method, we first sample a uniform random variable <span class="math">\(U\)</span> between <span class="math">\(0\)</span> and <span class="math">\(1\)</span>, then set <span class="math">\(X_{n+1} = 0\)</span> if <span class="math">\(U \leq P_{i0}\)</span>, <span class="math">\(X_{n+1} = 1\)</span> if <span class="math">\(P_{i0} &lt; U \leq P_{i1}\)</span>. In general, we would set <span class="math">\(X_{n+1} = j\)</span> if <span class="math">\(\sum_{k=0}^{j-1}P_{ik} \leq U &lt; \sum_{k=0}^{j}P_{ik}\)</span>.</p>
<p>When <span class="math">\(X_n=i\)</span> and there are <span class="math">\(S\)</span> possible states, instead of inverse transform sampling, we could also think of <span class="math">\(X_{n+1}\)</span> as a single draw from a multinomial distribution with probabilities equal to the <span class="math">\(i\)</span>-th row of <span class="math">\(P = (P_{i0},\ldots,P_{iS})\)</span>. This is how we will simulate our Markov chains below.</p>
<div id="general-algorithm" class="section level2">
<h2>General Algorithm</h2>
<p>Here we present a general algorithm for simulating a discrete Markov chain assuming we have <span class="math">\(S\)</span> possible states.</p>
<ol style="list-style-type: decimal">
<li>Obtain the <span class="math">\(S\times S\)</span> probability transition matrix <span class="math">\(P\)</span></li>
<li>Set <span class="math">\(t = 0\)</span></li>
<li>Pick an initial state <span class="math">\(X_t=i\)</span>. We can represent this as a vector of length <span class="math">\(S\)</span> with a <span class="math">\(1\)</span> in the <span class="math">\(i\)</span>-th component, and zeros elsewhere. Let this state vector be <span class="math">\(s_t = [0, 0,\ldots 1,\ldots, 0, 0]\)</span></li>
<li>For t = 1…T:
<ol style="list-style-type: decimal">
<li>Obtain the row of <span class="math">\(P\)</span> corresponding to the current state: <span class="math">\(p = sP\)</span></li>
<li>Let <span class="math">\(X_t\)</span> be a random draw from a multinomial distribution with probability vector <span class="math">\(p\)</span>. Assume this next state is <span class="math">\(j\)</span></li>
<li>Set the state vector <span class="math">\(s_t\)</span> to a vector whose <span class="math">\(j\)</span>-th component is 1, and zero otherwise</li>
</ol></li>
</ol>
</div>
</div>
<div id="limiting-probabilities" class="section level1">
<h1>Limiting Probabilities</h1>
<p>Let <span class="math">\(\pi^{(0)}\)</span> be our initial probability vector. For example, if we had a 3 state Markov chain with <span class="math">\(\pi^{(0)} = [0.5, 0.1, 0.4]\)</span>, this would tell us that our chain has a 50% probability of starting in state 1, a 10% probability of starting in state 2, and a 40% probability of starting in state 3. If we wanted to set our initial state to 1, we would have <span class="math">\(\pi^{(0)} = [1, 0, 0]\)</span>.</p>
<p>Let <span class="math">\(P\)</span> be our probability transition matrix. Recall from the note on discrete Markov chains that the probability vector after <span class="math">\(n\)</span> steps is equal to: <span class="math">\[\pi^{(n)} = \pi^{(0)}P^n\]</span> where <span class="math">\(P^n\)</span> is the matrix <span class="math">\(P\)</span> raised to the <span class="math">\(n\)</span>-th power.</p>
<p>With the facts above, we could keep track of our probability vector <span class="math">\(\pi^{(n)}\)</span> as we simulate the Markov chain as follows:</p>
<ol style="list-style-type: decimal">
<li>Obtain probability transition matrix <span class="math">\(P\)</span><br /></li>
<li>Set <span class="math">\(P_n = P\)</span><br /></li>
<li>For t = 1…T:
<ol style="list-style-type: decimal">
<li>Set <span class="math">\(\pi^{(n)} = \pi^{(0)}P_n\)</span><br /></li>
<li>Set <span class="math">\(P_n = P_nP\)</span></li>
</ol></li>
</ol>
<p>We implement an R function to simulate discrete Markov chains below. Here are two details about the implementation that will help you read the code:<br />* This function lets us run multiple Markov chains at once. Many of the vectors we talked about above are therefore represented as matrices, one vector for each chain.<br />* We initialize <span class="math">\(\pi^{(0)}\)</span> and <span class="math">\(s_0\)</span> so that the chain is forced to start in state 1 (i.e <span class="math">\(s_0 = \pi^{(0)} = (1,0,0,\ldots,0)\)</span>).</p>
<pre class="r"><code># simulate discrete Markov chains
run.mc.sim &lt;- function( P,   # probability transition matrix
                        num.iters=50, 
                        num.chains=150 )
  {
  
  # number of possible states
  num.states &lt;- nrow(P)
  
  # states X_t for all chains
  states     &lt;- matrix(NA, ncol=num.chains, nrow=num.iters)
  
  # probability vectors pi^n through time
  all_probs  &lt;- matrix(NA, nrow=num.iters, ncol=num.states)
  
  # intial state matrix for all chains (row k is s_t for chain k)
  # forces chains to start in state 1
  s_0       &lt;- matrix(0, nrow=num.chains, ncol=num.states)
  s_0[,1]   &lt;- 1
  pi_0      &lt;- s_0[1,]

  # initialize variables for first state 
  P_n           &lt;- P
  all_probs[1,] &lt;- pi_0
  states[1,]    &lt;- 1
  s_t           &lt;- s_0
  
  for(t in 2:num.iters) {
    
    # pi^n for this iteration
    pi_n           &lt;- pi_0 %*% P_n
    all_probs[t,]  &lt;- pi_n
    
    # probability vector to simulating next state X_{n+1}
    p              &lt;- s_t %*% P
    
    # sample states for each chain
    for(chain_num in seq_len(num.chains)) {
      s_t[chain_num,]       &lt;- t(rmultinom(1, 1, p[chain_num,]))
      states[t,chain_num]   &lt;- which(s_t[chain_num,] == 1)
    }
    
    # update probability transition matrix
    P_n           &lt;- P_n %*% P
  }
  return(list(all.probs=all_probs, states=states))
}</code></pre>
</div>
<div id="simulation-1-3x3-example" class="section level1">
<h1>Simulation 1: 3x3 example</h1>
<p>Assume our probability transition matrix is: <span class="math">\[P = \begin{bmatrix}
    0.7 &amp; 0.2 &amp; 0.1 \\
    0.4 &amp; 0.6 &amp; 0 \\
    0   &amp; 1   &amp; 0 
\end{bmatrix}\]</span></p>
<p>We initialize this matrix in R below:</p>
<pre class="r"><code># setup transition matrix 
P &lt;- t(matrix(c( 0.7, 0.2, 0.1, 
                 0.4, 0.6,   0, 
                   0,   1,   0  ), nrow=3, ncol=3))</code></pre>
<div id="finding-the-stationary-distribution" class="section level2">
<h2>Finding the stationary distribution</h2>
<p>Every irreducible finite state space Markov chain has a unique stationary distribution. All of the examples we consider in this note are irreducible. Recall that the stationary distribution <span class="math">\(\pi\)</span> is the vector such that <span class="math">\[\pi = \pi P\]</span>.</p>
<p>We can find our stationary distribution by solving the following linear system: <span class="math">\[\begin{align*}
0.7\pi_1 + 0.4\pi_2  &amp;= \pi_1 \\
0.2\pi_1 + 0.6\pi_2 + \pi_3 &amp;= \pi_2 \\
0.1\pi_1 &amp;= \pi_3
\end{align*}\]</span> subject to <span class="math">\(\pi_1 + \pi_2 + \pi_3 = 1\)</span>. Putting these four equations together and moving all of the variables to the left hand side, we get the following linear system: <span class="math">\[\begin{align*}
-0.3\pi_1 + 0.4\pi_2  &amp;= 0 \\
0.2\pi_1 + -0.4\pi_2 + \pi_3 &amp;= 0 \\
0.1\pi_1 - \pi_3 &amp;= 0 \\
\pi_1 + \pi_2 + \pi_3 &amp;= 1
\end{align*}\]</span></p>
<p>We will define the linear system in matrix notation: <span class="math">\[\underbrace{\begin{bmatrix}
    -0.3 &amp;  0.4 &amp; 0  \\
     0.2 &amp; -0.4 &amp; 1  \\
     0.1 &amp;    0 &amp; 1  \\
     1   &amp;  1   &amp; 1 
\end{bmatrix}}_A \begin{bmatrix}
\pi_1 \\
\pi_2 \\
\pi_3 
\end{bmatrix} = \underbrace{\begin{bmatrix}
0 \\
0 \\ 
0 \\
1
\end{bmatrix}}_b \\
A\pi = b\]</span></p>
<p>Since this linear system has more equations than unknowns, it is an overdeterminted system. Recall from linear algebra that an overdetermined system is consistent (i.e. we can solve for <span class="math">\(\pi\)</span> exactly) when <span class="math">\(b\)</span> is in the column space of <span class="math">\(A\)</span>. We can check this numerically by obtaining the rank of <span class="math">\(A\)</span>, then obtaining the rank of an augmented matrix with <span class="math">\(b\)</span> appended as a column of <span class="math">\(A\)</span>.</p>
<pre class="r"><code>library(Matrix)
A        &lt;- matrix(c(-0.3, 0.2, 0.1, 1, 0.4, -0.4, 0, 1, 0, 1, -1, 1 ), ncol=3,nrow=4)
b        &lt;- c(0,0,0, 1)
rank.A   &lt;- as.numeric(rankMatrix(A))
rank.Ab  &lt;- as.numeric(rankMatrix(cbind(A,b)))
print(paste(&quot;The rank of A =&quot;, rank.A, &quot;and the rank of the augmented matrix =&quot;, rank.Ab))</code></pre>
<pre><code>[1] &quot;The rank of A = 3 and the rank of the augmented matrix = 3&quot;</code></pre>
<p>We see that <span class="math">\(A\)</span> has full column rank, and that the rank is unchanged when we add <span class="math">\(b\)</span> as a column. Therefore, <span class="math">\(b\)</span> is in the column space of <span class="math">\(A\)</span>, and this system is consistent. We can find <span class="math">\(\pi\)</span> by solving the normal equations: <span class="math">\[A^TA\pi = A^Tb\]</span></p>
<p>We use the solve function in R to solve for the stationary distribution <span class="math">\(\pi\)</span>:</p>
<pre class="r"><code>pi        &lt;- drop(solve(t(A) %*% A, t(A) %*% b))
names(pi) &lt;- c(&#39;state.1&#39;, &#39;state.2&#39;, &#39;state.3&#39;)
pi </code></pre>
<pre><code>   state.1    state.2    state.3 
0.54054054 0.40540541 0.05405405 </code></pre>
<p>We find that: <span class="math">\[\begin{align*}
\pi_1 \approx 0.54, \pi_2 \approx 0.41, \pi_3 \approx 0.05
\end{align*}\]</span></p>
<p>Therefore, with proper conditions (see below), we expect the Markov chain to spend more time in states 1 and 2 as the chain evolves.</p>
<p>Now we will use the function we wrote in the previous section to check this result numerically.</p>
<pre class="r"><code>sim1 &lt;- run.mc.sim(P)</code></pre>
<p>Our function returns a list containing two matrices. The second matrix called “states”&quot; contains the states of each of our simulated chains through time. Recall that our state space is <span class="math">\(\{1,2,3\}\)</span>. Below, we first visualize how 5 of these chains evolve through time:</p>
<pre class="r"><code>states &lt;- sim1[[2]]
matplot(states[,1:5], type=&#39;l&#39;, lty=1, col=1:5, ylim=c(0,4), ylab=&#39;state&#39;, xlab=&#39;time&#39;)
abline(h=1, lty=3)
abline(h=3, lty=3)</code></pre>
<p><img src="figure/simulate_discrete_chains.Rmd/unnamed-chunk-6-1.png" title="" alt="" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="the-limiting-distribution" class="section level2">
<h2>The limiting distribution</h2>
<p>The first matrix we get from our function contains <span class="math">\(\pi^{(n)}\)</span> through time. We can see how <span class="math">\(\pi^{(n)}\)</span> evolves as <span class="math">\(n\)</span> grows, and we can check if it converges to the stationary distribution we found above. For irreducible finite state Markov chains, note that <span class="math">\(\pi^{(n)}\)</span> converges if and only if the Markov chain is aperiodic. In this note, we only consider finite, irreducible, and aperiodic Markov chains.</p>
<p>From <span class="math">\(\pi^{(n)}\)</span>, we plot the time evolution of the probability of being in each state:</p>
<pre class="r"><code>all.probs &lt;- sim1[[1]]
matplot(all.probs, type=&#39;l&#39;, col=1:3, lty=1, ylab=&#39;probability&#39;, xlab=&#39;time&#39;)
legend(&#39;topright&#39;, c(&#39;state.1&#39;, &#39;state.2&#39;, &#39;state.3&#39;), lty=1, col=1:3)</code></pre>
<p><img src="figure/simulate_discrete_chains.Rmd/unnamed-chunk-7-1.png" title="" alt="" width="672" style="display: block; margin: auto;" /></p>
<p>Indeed, we see that these probabilities quickly converge. Just by eye-balling the plot, we can see that the final probabilities are about equal to the stationary distribution <span class="math">\(\pi\)</span> we found above.</p>
<p>By inspecting the actual values, we can confirm that the values of <span class="math">\(\pi^{(n)}\)</span> converge to the vector <span class="math">\(\pi\)</span> exactly. The first row in the matrix below is from the simulation, and the second row is the quantity we obtained by solving the normal equations:</p>
<pre class="r"><code>results1           &lt;- t(data.frame(pi_n = all.probs[50,], pi = pi))
colnames(results1) &lt;- c(&#39;state.1&#39;, &#39;state.2&#39;, &#39;state.3&#39;)
results1</code></pre>
<pre><code>       state.1   state.2    state.3
pi_n 0.5405405 0.4054054 0.05405405
pi   0.5405405 0.4054054 0.05405405</code></pre>
<p>Finally, we can also plot the proportion of chains that are in each state through time. These should roughly equal the probability vectors above, with some noise due to random chance:</p>
<pre class="r"><code>state.probs &lt;- t(apply(apply(sim1[[2]], 1, function(x) table(factor(x, levels=1:3))), 2, function(x) x/sum(x)))
matplot(state.probs[1:50,], col=1:3, lty=1, type=&#39;l&#39;, ylab=&#39;empirical probability&#39;, xlab=&#39;time&#39;)
legend(&#39;topright&#39;, c(&#39;state.1&#39;, &#39;state.2&#39;, &#39;state.3&#39;), lty=1, col=1:3)</code></pre>
<p><img src="figure/simulate_discrete_chains.Rmd/unnamed-chunk-9-1.png" title="" alt="" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="simulation-2-8x8-example" class="section level1">
<h1>Simulation 2: 8x8 example</h1>
<p>Next we will quickly do two similar, but larger, experiments with the size of our state space equal to 8. Assume our probability transition matrix is: <span class="math">\[P = \begin{bmatrix}
    0.33 &amp; 0.66 &amp; 0     &amp; 0   &amp; 0    &amp; 0     &amp; 0    &amp; 0 \\
    0.33 &amp; 0.33 &amp; 0.33  &amp; 0   &amp; 0    &amp; 0     &amp; 0    &amp; 0 \\
    0    &amp; 0.33 &amp; 0.33 &amp; 0.33 &amp; 0    &amp; 0     &amp; 0    &amp; 0 \\
    0    &amp; 0    &amp; 0.33 &amp; 0.33 &amp; 0.33 &amp; 0     &amp; 0    &amp; 0 \\
    0    &amp; 0    &amp; 0    &amp; 0.33 &amp; 0.33 &amp; 0.33  &amp; 0    &amp; 0   \\
    0    &amp; 0    &amp; 0    &amp; 0    &amp; 0.33 &amp; 0.33  &amp; 0.33 &amp; 0   \\
    0    &amp; 0    &amp; 0    &amp; 0    &amp; 0    &amp; 0.33  &amp; 0.33 &amp; 0.33 \\
    0    &amp; 0    &amp; 0    &amp; 0    &amp; 0    &amp; 0     &amp; 0.66 &amp; 0.33 \\
\end{bmatrix}\]</span></p>
<p>We first initialize our transition matrix in R:</p>
<pre class="r"><code>P &lt;- t(matrix(c( 1/3, 2/3,   0,   0,  0,   0,   0,   0,
                 1/3, 1/3, 1/3,   0,  0,   0,   0,   0,
                   0, 1/3, 1/3, 1/3,  0,   0,   0,   0,
                   0,   0, 1/3, 1/3, 1/3,  0,   0,   0,
                   0,   0,   0, 1/3, 1/3, 1/3,  0,   0,
                   0,   0,   0,   0, 1/3, 1/3, 1/3,  0,
                   0,   0,   0,   0,   0, 1/3, 1/3, 1/3,
                   0,   0,   0,   0,   0,   0, 2/3, 1/3), nrow=8, ncol=8))</code></pre>
<p>After briefly studying this matrix, we can see that for states 2 through 7, this transition matrix forces the chain to either stay in the current state or move one state up or down, all with equal probability. For the edge cases, states 1 and 8, the chain can either stay or reflect towards the middle states. Since it’s “easier” to get to one of the middle states (either from above or below), we should see that the probabilities for these states converge to a higher number than the states on the boundaries.</p>
<p>Now we run our simulations with the transition matrix above:</p>
<pre class="r"><code>sim2a &lt;- run.mc.sim(P)</code></pre>
<p>and now plot 5 of the chains through time below:</p>
<pre class="r"><code>states &lt;- sim2a[[2]]
matplot(states[,1:5], type=&#39;l&#39;, lty=1, col=1:5, ylim=c(0,9), ylab=&#39;state&#39;, xlab=&#39;time&#39;)
abline(h=1, lty=3)
abline(h=8, lty=3)</code></pre>
<p><img src="figure/simulate_discrete_chains.Rmd/unnamed-chunk-12-1.png" title="" alt="" width="672" style="display: block; margin: auto;" /></p>
<p>Next we inpsect <span class="math">\(\pi^{(n)}\)</span> through time:</p>
<pre class="r"><code>all.probs &lt;- sim2a[[1]]
matplot(all.probs, type=&#39;l&#39;, col=1:8, lty=1, ylab=&#39;probability&#39;,
        xlab=&#39;time&#39;, ylim=c(0, 0.5))
legend(&#39;topright&#39;, paste(&#39;state.&#39;, 1:8, sep=&#39;&#39;), lty=1, col=1:8)</code></pre>
<p><img src="figure/simulate_discrete_chains.Rmd/unnamed-chunk-13-1.png" title="" alt="" width="672" style="display: block; margin: auto;" /> These results match our intuition above. The probability of being in states 1 and 8 converge to smaller values than the others.</p>
<p>Now we alter the transition matrix above to encourage the chain to stay in states 4 and 5: <span class="math">\[P = \begin{bmatrix}
    0.33 &amp; 0.66 &amp; 0     &amp; 0   &amp; 0    &amp; 0     &amp; 0    &amp; 0 \\
    0.33 &amp; 0.33 &amp; 0.33  &amp; 0   &amp; 0    &amp; 0     &amp; 0    &amp; 0 \\
    0    &amp; 0.08 &amp; 0.08 &amp; 0.84 &amp; 0    &amp; 0     &amp; 0    &amp; 0 \\
    0    &amp; 0    &amp; 0.08 &amp; 0.84 &amp; 0.08 &amp; 0     &amp; 0    &amp; 0 \\
    0    &amp; 0    &amp; 0    &amp; 0.08 &amp; 0.84 &amp; 0.08  &amp; 0    &amp; 0   \\
    0    &amp; 0    &amp; 0    &amp; 0    &amp; 0.84 &amp; 0.08  &amp; 0.08 &amp; 0   \\
    0    &amp; 0    &amp; 0    &amp; 0    &amp; 0    &amp; 0.33  &amp; 0.33 &amp; 0.33 \\
    0    &amp; 0    &amp; 0    &amp; 0    &amp; 0    &amp; 0     &amp; 0.66 &amp; 0.33 \\
\end{bmatrix}\]</span></p>
<p>and initialize the transition matrix in R:</p>
<pre class="r"><code>P &lt;- t(matrix(c( 1/3,   2/3,    0,    0,    0,    0,    0,   0,
                 1/3,   1/3,  1/3,    0,    0,    0,    0,   0,
                   0,  .5/6, .5/6,  5/6,    0,    0,    0,   0,
                   0,     0, .5/6,  5/6, .5/6,    0,    0,   0,
                   0,     0,    0, .5/6,  5/6, .5/6,    0,   0,
                   0,     0,    0,    0,  5/6, .5/6, .5/6,   0,
                   0,     0,    0,    0,    0,  1/3,  1/3, 1/3,
                   0,     0,    0,    0,    0,    0,  2/3, 1/3 ), nrow=8, ncol=8))</code></pre>
<pre class="r"><code>sim2b &lt;- run.mc.sim(P)</code></pre>
<p>Below we inspect <span class="math">\(\pi^{(n)}\)</span> through time and see that the probability vector converges to a vector placing most of the probability mass on states 4 and 5.</p>
<pre class="r"><code>all.probs &lt;- sim2b[[1]]
matplot(all.probs, type=&#39;l&#39;, col=1:8, lty=1, ylab=&#39;probability&#39;,
        xlab=&#39;time&#39;, ylim=c(0,1.2))
legend(&#39;topright&#39;, paste(&#39;state.&#39;, 1:8, sep=&#39;&#39;), lty=1, col=1:8)</code></pre>
<p><img src="figure/simulate_discrete_chains.Rmd/unnamed-chunk-16-1.png" title="" alt="" width="672" style="display: block; margin: auto;" /></p>
<p>Finally we confirm that our empirical probabilities also exhibit similar behavior:</p>
<pre class="r"><code>state.probs &lt;- t(apply(apply(sim2b[[2]], 1, function(x) table(factor(x, levels=1:8))), 2, function(x) x/sum(x)))
matplot(state.probs[1:50,], col=1:8, lty=1, type=&#39;l&#39;, ylab=&#39;empirical probability&#39;, xlab=&#39;time&#39;, ylim=c(0,1.2))
legend(&#39;topright&#39;, paste(&#39;state.&#39;, 1:8, sep=&#39;&#39;), lty=1, col=1:8)</code></pre>
<p><img src="figure/simulate_discrete_chains.Rmd/unnamed-chunk-17-1.png" title="" alt="" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="session-information" class="section level1">
<h1>Session information</h1>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 3.2.2 (2015-08-14)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.10.5 (Yosemite)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] Matrix_1.2-3 knitr_1.11  

loaded via a namespace (and not attached):
 [1] magrittr_1.5    formatR_1.2.1   tools_3.2.2     htmltools_0.3  
 [5] yaml_2.1.13     stringi_1.0-1   rmarkdown_0.9.2 grid_3.2.2     
 [9] stringr_1.0.0   digest_0.6.8    lattice_0.20-33 evaluate_0.8   </code></pre>
</div>


<!-- some extra javascript for older browsers -->
<script type="text/javascript" src="libs/polyfill.js"></script>

<script>

// manage active state of menu based on current page
$(document).ready(function () {

    // active menu
    href = window.location.pathname
    href = href.substr(href.lastIndexOf('/') + 1)
    $('a[href="' + href + '"]').parent().addClass('active');

    // manage active menu header
    if (href.startsWith('authoring_'))
      $('a[href="' + 'authoring' + '"]').parent().addClass('active');
    else if (href.endsWith('_format.html'))
      $('a[href="' + 'formats' + '"]').parent().addClass('active');
    else if (href.startsWith('developer_'))
      $('a[href="' + 'developer' + '"]').parent().addClass('active');

});

</script>

</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
